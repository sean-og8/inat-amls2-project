{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "image_dir=\"data/train_mini/2021_train_mini\"\n",
    "json_file=\"data/train_mini/train_mini.json\"\n",
    "    \n",
    "with open(json_file, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Extract images and annotations\n",
    "image_metadata = metadata[\"images\"]  # List of image metadata dicts\n",
    "annotations = {ann[\"image_id\"]: ann[\"category_id\"] for ann in metadata[\"annotations\"]}  # Map image_id to category_id\n",
    "categories = {cat[\"id\"]: cat[\"name\"] for cat in metadata[\"categories\"]}  # Map category_id to category name\n",
    "# Create a mapping: {filename -> (latitude, longitude, category_id)}\n",
    "image_data = {}\n",
    "for img in image_metadata:\n",
    "    #print(img[\"file_name\"])\n",
    "    #print(img[\"file_name\"].split(\"/\")[-2:])\n",
    "    filename = img[\"file_name\"].split(\"/\")[-1]\n",
    "    print(filename)\n",
    "    image_id = img[\"id\"]\n",
    "    lat, long = img[\"latitude\"], img[\"longitude\"]\n",
    "    category_id = annotations.get(image_id, -1)  # Default to -1 if not found\n",
    "    image_data[filename] = (lat, long, category_id)\n",
    "    break\n",
    "# Get all valid image filenames that exist in metadata and directory\n",
    "#self.image_files = [f for f in os.listdir(image_dir) if f in self.image_data]\n",
    "image_files = []\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file in image_data:\n",
    "            print(str(root + \"/\" + file).split(\"/\")[-2:])\n",
    "            print(str(\"/\" + root + \"/\" + file).split(\"\\\\\")[-1])\n",
    "            image_files.append(str(\"/\" + root + \"/\" + file).split(\"\\\\\")[-1])\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# need to normalise lat long data and add in the date data (month will do)\n",
    "\n",
    "class ImageDatasetWithContext(Dataset):\n",
    "    def __init__(self, image_dir, json_file, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load metadata JSON\n",
    "        with open(json_file, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "        # Extract images and annotations\n",
    "        self.image_metadata = metadata[\"images\"]  # List of image metadata dicts\n",
    "        self.annotations = {ann[\"image_id\"]: ann[\"category_id\"] for ann in metadata[\"annotations\"]}  # Map image_id to category_id\n",
    "        self.categories = {cat[\"id\"]: cat[\"name\"] for cat in metadata[\"categories\"]}  # Map category_id to category name\n",
    "        # Create a mapping: {filename -> (latitude, longitude, category_id)}\n",
    "        self.image_data = {}\n",
    "        for img in self.image_metadata:\n",
    "            filename = img[\"file_name\"].split(\"/\")[-1]\n",
    "            image_id = img[\"id\"]\n",
    "\n",
    "            lat, long = img[\"latitude\"], img[\"longitude\"]\n",
    "            if type(img[\"latitude\"]) is not float or img[\"latitude\"] > 180 or img[\"latitude\"] < -180:\n",
    "                lat = 0\n",
    "            if type(img[\"longitude\"]) is not float or img[\"longitude\"] > 180 or img[\"longitude\"] < -180:\n",
    "                long = 0   \n",
    "\n",
    "            # normalise to be in range 0 - 1\n",
    "            lat = (lat + 180) / 360\n",
    "            long = (long + 180) / 360\n",
    "\n",
    "            \n",
    "            category_id = self.annotations.get(image_id, -1)  # Default to -1 if not found\n",
    "            self.image_data[filename] = (lat, long, category_id)\n",
    "        # Get all valid image filenames that exist in metadata and directory\n",
    "        #self.image_files = [f for f in os.listdir(image_dir) if f in self.image_data]\n",
    "        self.image_files = []\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                if file in self.image_data:\n",
    "                    self.image_files.append(str(\"/\" + root + \"/\" + file).split(\"\\\\\")[-1])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path= self.image_files[idx]\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        image_path = os.path.join(self.image_dir, file_path)\n",
    "\n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Retrieve lat/long and category\n",
    "        lat, long, category_id = self.image_data[file_name]\n",
    "\n",
    "        # Convert to tensors\n",
    "        context_features = torch.tensor([lat, long], dtype=torch.float32)\n",
    "        #category_label = torch.tensor(category_id, dtype=torch.long)\n",
    "\n",
    "        return image, context_features, category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDatasetWithContext(image_dir=\"data/train_mini/2021_train_mini\", json_file=\"data/train_mini/train_mini.json\", transform=train_transform)\n",
    "validation_data = ImageDatasetWithContext(image_dir=\"data/validation/2021_valid\", json_file=\"data/validation/val.json\", transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(validation_data, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Training samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(validation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[155550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_indices = []\n",
    "with open('bird_indices.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bird_indices.append(int(line[0:-1]))\n",
    "\n",
    "bird_test_indices = []\n",
    "with open('bird_val_indices.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bird_test_indices.append(int(line[0:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all indices where the target (label) corresponds to birds\n",
    "# Create a subset dataset containing only birds\n",
    "train_data_birds = Subset(train_data, bird_indices)\n",
    "\n",
    "# label_index_map = {}\n",
    "# index_list = [] \n",
    "# label_list = []\n",
    "\n",
    "# for i, (_, _, label) in enumerate(train_data_birds):\n",
    "#     index_list.append(i)\n",
    "#     label_list.append(label)\n",
    "# # now, for each label, randomly select 20% of indices, these will become the val set. \n",
    "# index_list_train, index_list_val, labels_train, labels_val = train_test_split(\n",
    "# index_list, label_list, test_size=0.2, random_state=42, stratify=label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_list(list, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for line in list:\n",
    "            f.write(f\"{line}\\n\")\n",
    "    return\n",
    "\n",
    "# output_list(index_list_train, \"index_list_train.csv\")\n",
    "# output_list(index_list_val, \"index_list_val.csv\")\n",
    "# output_list(labels_train, \"labels_train.csv\")\n",
    "# output_list(labels_val, \"labels_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(file_name):\n",
    "    output_list = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            output_list.append(int(line[0:-1]))\n",
    "    return output_list\n",
    "\n",
    "index_list_train = read_list_from_file(\"index_list_train.csv\") \n",
    "index_list_val = read_list_from_file(\"index_list_val.csv\") \n",
    "labels_train = read_list_from_file(\"labels_train.csv\") \n",
    "labels_val = read_list_from_file(\"labels_val.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_birds = Subset(train_data_birds, index_list_val)\n",
    "train_data_birds = Subset(train_data_birds, index_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataLoader for the filtered dataset\n",
    "train_loader_birds = DataLoader(train_data_birds, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader_birds = DataLoader(val_data_birds, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "# use validation set from problem as the unseen test set\n",
    "test_data_birds = Subset(validation_data, bird_test_indices)\n",
    "test_loader_birds = DataLoader(test_data_birds, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Filtered train dataset contains {len(train_data_birds)} bird images.\")\n",
    "print(f\"Filtered val dataset contains {len(val_data_birds)} bird images.\")\n",
    "print(f\"Filtered test dataset contains {len(test_data_birds)} bird images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(labels_val))\n",
    "print(Counter(labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data_birds[98][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data_birds[4][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "#dataiter = iter(train_loader_birds)\n",
    "#images, _, labels = next(dataiter)\n",
    "#print(next(dataiter))\n",
    "# show images\n",
    "#imshow(make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_cat_list = []\n",
    "\n",
    "for file_name in train_data.image_files:\n",
    "    full_species = file_name.split(\"/\")[0]\n",
    "    if \"Animalia_Chordata_Aves\" in full_species and full_species not in bird_cat_list:\n",
    "        bird_cat_list.append(full_species)\n",
    "n_classes = len(bird_cat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_labels(labels):\n",
    "    return (labels - 3111).long()  \n",
    "\n",
    "\n",
    "def log_metrics_tensor_board(data_type, accuracy, top_5_accuracy, loss, epoch ):\n",
    "    writer.add_scalar(f\"Loss -  {data_type}\", loss, epoch)\n",
    "    writer.add_scalar(f\"Accuracy -  {data_type}\", 100 * accuracy, epoch)\n",
    "    writer.add_scalar(f\"Top 5 Accuracy - {data_type}\", 100 * top_5_accuracy, epoch)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_model(model, criterion, optimizer,  epoch, model_name):\n",
    "    torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "                }, f\"runs/model_pretrained_{model_name}.pth\")\n",
    "    return\n",
    "\n",
    "\n",
    "def run_epoch(model, loader, criterion, optimizer=None, epoch=0, mode=\"train\"):\n",
    "    is_train = mode == \"train\"\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    top_5_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):  # Only compute gradients during training\n",
    "        for images, contextual_data, labels in loader: ##HERE\n",
    "            images, contextual_data, labels = images.to(device), contextual_data.to(device), labels.to(device) ##HERE\n",
    "            labels = remap_labels(labels).to(device)\n",
    "            outputs = model(images, contextual_data)  # Forward pass  ##HERE\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            # count total correct predicitions in batch\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            # count total matches of label in top 5 class predictions \n",
    "            _, top_5_predicted = outputs.topk(5, dim=1)\n",
    "            top_5_correct += torch.isin(labels, top_5_predicted).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    top_5_accuracy = top_5_correct / total\n",
    "    log_metrics_tensor_board(mode, accuracy, top_5_accuracy, avg_loss, epoch)\n",
    "\n",
    "    print(f\"{mode.capitalize()} Accuracy: {100 * accuracy:.2f}%\")\n",
    "    print(f\"Top 5 {mode.capitalize()} Accuracy: {100 * top_5_accuracy:.2f}%\")\n",
    "    print(f\"Epoch {epoch+1} - {mode.capitalize()} Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def train_model(model, model_name, train_loader, val_loader, criterion, optimizer, epochs=5, early_stop_limit=5):\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_count = 0\n",
    "    # lists to track of loss and accuracy metrics\n",
    "    train_loss_list, val_loss_list = [], []\n",
    "    train_acc_list, val_acc_list = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer, epoch, mode=\"train\")\n",
    "        # if no val loader, evaluate stopping based on train metrics (e.g. when training on validation after training on train before evaluating on test)\n",
    "        if val_loader is None:\n",
    "            val_loss, val_acc = train_loss, train_acc\n",
    "        else:\n",
    "            val_loss, val_acc = run_epoch(model, val_loader, criterion, None, epoch, mode=\"validation\")\n",
    "        # store metrics\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_loss_list.append(val_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        # early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_count = 0\n",
    "            # save best model so far\n",
    "            save_model(model, criterion, optimizer,  epoch, model_name)\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "        if early_stop_count == early_stop_limit:\n",
    "            break\n",
    "    eval_metrics = {\n",
    "            \"train_loss\": train_loss_list,\n",
    "            \"val_loss\": val_loss_list,\n",
    "            \"train_acc\": train_acc_list,\n",
    "            \"val_acc\": val_acc_list\n",
    "        }\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_ContextualData(nn.Module):\n",
    "    def __init__(self, num_classes, contextual_dim, tune_all_layers=True):\n",
    "        super(EfficientNet_ContextualData, self).__init__()\n",
    "\n",
    "        # Load EfficientNet-B0 with pretrained weights\n",
    "        self.weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        self.pretrained_model = efficientnet_b0(weights=self.weights)\n",
    "\n",
    "        # Remove classifier by keeping only the feature extractor cnn layers\n",
    "        self.feature_extractor = self.pretrained_model.features\n",
    "\n",
    "        # Freeze or unfreeze the training of cnn layers\n",
    "        if not tune_all_layers:\n",
    "            for param in self.feature_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # get pretrained model number of output features\n",
    "        cnn_out_features = self.pretrained_model.classifier[1].in_features\n",
    "        \n",
    "        # Define final classifier layer combining CNN + Contextual Data\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cnn_out_features + contextual_dim, 2048),  # Combine features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, num_classes)  # Final output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, image_data, contextual_data):\n",
    "\n",
    "        # put image data through feature extactor \n",
    "        cnn_output = self.feature_extractor(image_data)\n",
    "        cnn_output = torch.mean(cnn_output, dim=[2, 3])  # Global average pooling\n",
    "        # flatten CNN output data\n",
    "        cnn_output = cnn_output.view(cnn_output.size(0), -1)  \n",
    "\n",
    "        # combine CNN output with contextual data\n",
    "        combined_input = torch.cat((cnn_output, contextual_data), dim=1)\n",
    "        # Pass through the classifier for final prediction\n",
    "        output = self.classifier(combined_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_birds[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader_birds:\n",
    "    print(\"Batch loaded successfully!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader_birds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient net model \n",
    "\n",
    "model = EfficientNet_ContextualData(n_classes, 2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "eval_metrics = train_model(model, \"efficientnet_contextual_data_b0\", train_loader_birds, val_loader_birds, criterion, optimizer, epochs=100, early_stop_limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(f\"runs/model_pretrained_efficientnet_b0.pth\")\n",
    "\n",
    "# turn to function def rebuild model\n",
    "# Load the pretrained EfficientNet model\n",
    "trained_model = efficientnet_b0(pretrained=False) \n",
    "\n",
    "trained_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(trained_model.classifier[1].in_features, n_classes)\n",
    ")\n",
    "\n",
    "for param in trained_model.parameters():\n",
    "    param.requires_grad = True  # Enable fine tune training on all layers\n",
    "\n",
    "trained_model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(trained_model.parameters(), lr=0.001)  # Use the same optimizer as before\n",
    "# Load model and optimizer states\n",
    "trained_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "train_model(trained_model, \"efficientnet_b0_final\", val_loader_birds, None, criterion, optimizer, epochs=5, early_stop_limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test\n",
    "val_loss, val_acc = run_epoch(trained_model, test_loader_birds, criterion, None, epoch=0, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(trained_model, criterion, optimizer, epoch=18, model_name=\"efficientnet_b0_full_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_classes = [cat for cat in train_data.all_categories if \"Animalia_Chordata_Aves\" in cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in bird_classes}\n",
    "total_pred = {classname: 0 for classname in bird_classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_birds:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = remap_labels(labels).to(device)\n",
    "        outputs = trained_model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[bird_classes[label]] += 1\n",
    "            total_pred[bird_classes[label]] += 1\n",
    "# turn into dataframe and sort by smallest success classes\n",
    "# then create confusion matrix for all classes - find the biggest misses\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in bird_classes}\n",
    "total_pred = {classname: 0 for classname in bird_classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader_birds:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = remap_labels(labels).to(device)\n",
    "        outputs = trained_model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[bird_classes[label]] += 1\n",
    "            total_pred[bird_classes[label]] += 1\n",
    "# turn into dataframe and sort by smallest success classes\n",
    "# then create confusion matrix for all classes - find the biggest misses\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
